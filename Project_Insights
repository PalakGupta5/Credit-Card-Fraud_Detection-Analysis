Although digital transactions in India registered a 51% growth in 2018-19, their safety remains a concern. Fraudulent activities have increased severalfold, with around 52,304 cases of credit/debit card fraud reported in FY'19 alone. Due to this steep increase in banking frauds, it is the need of the hour to detect these fraudulent transactions in time in order to help consumers as well as banks, who are losing their credit worth each day. Machine learning can play a vital role in detecting fraudulent transactions.


Until now, you have learnt about the different types of machine learning models, but now you will learn which model to choose for your purpose and why. Understanding the models based on different scenarios is an important skill that a data scientist/machine learning engineer should possess. In addition, tuning your model is equally important to get the best fit for your given data.
 
By the end of this module, you will be able to understand how you can build a machine learning model capable of detecting fraudulent transactions. You will also learn how to handle class imbalances present in any data set, along with model selection and hyperparameter tuning.

Project Understanding
Imagine you get a call from your bank, and the customer care executive informs you that your card is about to expire in a week. Immediately, you check your card details and realise that it will expire in the next 8 days. Now, in order to renew your membership, the executive asks you to verify a few details such as your credit card number, the expiry date and the CVV number. Will you share these details with the executive?


In such situations, you need to be careful because the details that you might share with them could grant them unhindered access to your credit card account.
 
Here, we will understand frauds from a bank’s perspective and learn to what extent these frauds affect their business. Banks need to be cautious about their customers’ transactions, as they cannot afford to lose their customers’ money to fraudsters. Every fraud is a loss to the bank as the bank is responsible for the fraud transactions if it is reported within a certain time frame by the customer.

 Data Understanding
 
The data set includes credit card transactions made by European cardholders over a period of two days in September 2013. Out of a total of 2,84,807 transactions, 492 were fraudulent. This data set is highly unbalanced, with the positive class (frauds) accounting for just 0.172% of the total transactions. The data set has also been modified with Principal Component Analysis (PCA) to maintain confidentiality. Apart from ‘time’ and ‘amount’, all the other features (V1, V2, V3, up to V28) are the principal components obtained using PCA. The feature 'time' contains the seconds elapsed between the first transaction in the data set and the subsequent transactions. The feature 'amount' is the transaction amount. The feature 'class' represents class labelling, and it takes the value 1 in cases of fraud and 0 in others.
The distribution plots of the variables were Gaussian, which might indicate the effects of transformations that had already occurred on the data set

Project Pipeline

The project pipeline can be briefly summarized in the following four steps:

Data Understanding: Here, you need to load the data and understand the features present in it. This would help you choose the features that you will need for your final model.
 
Exploratory data analytics (EDA): Normally, in this step, you need to perform univariate and bivariate analyses of the data, followed by feature transformations, if necessary. For the current data set, because Gaussian variables are used, you do not need to perform Z-scaling. However, you can check if there is any skewness in the data and try to mitigate it, as it might cause problems during the model-building phase.

Can you think why skewness can be an issue while modelling? Well, some of the data points in a skewed distribution towards the tail may act as outliers for the machine learning models which are sensitive to outliers and hence that may cause a problem. Also, if the values of any independent feature are skewed, depending on the model, skewness may affect model assumptions or may impair the interpretation of feature importance. 
 

Train/Test Split: Now you are familiar with the train/test split, which you can perform in order to check the performance of your models with unseen data. Here, for validation, you can use the k-fold cross-validation method. You need to choose an appropriate k value so that the minority class is correctly represented in the test folds.
 
Model-Building/Hyperparameter Tuning: This is the final step at which you can try different models and fine-tune their hyperparameters until you get the desired level of performance.

Class Imbalance
 the data shows a high class imbalance. Over 2,00,000 cases are mapped to 0, but hardly 500 cases are mapped to 1. Any machine learning algorithm would work well when there is equal representation of each of the classes. However, in this case, no matter which model you build, the underlying algorithm will learn more about the non-fraudulent cases rather than the fraudulent ones. Therefore, the loss function optimisation will be heavily biased to the former type of data. This is known as the ‘minority class problem’.

 

Now, we can use certain methods to mitigate this problem. They are as follows:

Undersampling: In this method, you have the choice of selecting fewer data points from the majority class for your model-building process. In case you have only 500 data points in the minority class, you will also have to take 500 data points from the majority class; this will make the classes somewhat balanced. However, in practice, this method is not effective because you will lose over 99% of the original data.
Oversampling: Using this method, you can assign weights to randomly chosen data points from the minority class. This way, the occurrence of each data point will be multiplied by the assigned weight, and the machine learning algorithm will now be able to focus on this class while optimising the loss function. However, this method does not add any new information and may even exaggerate the existing information quite a bit

Undersampling and Oversampling
Synthetic Minority Over-Sampling Technique (SMOTE): In this process, you can generate new data points, which lie vectorially between two data points that belong to the minority class. These data points are randomly chosen and then assigned to the minority class. This method uses K-nearest neighbours to create random synthetic samples. The steps in this process are as follows:
Randomly selecting a minority point A
The k nearest neighbours for that data point belonging to the same are found and then a random point, B form the k_neighbours is selected.
Specifying a random value in the range [0, 1] as 
λ
.
Generating and placing a synthetic sample between the two points A and B on the vector located at 
λ
% from the original point A.

 ADAptive SYNthetic (ADASYN): This is similar to SMOTE, with a minor change in the generation of synthetic sample points for minority data points. For a particular data point, the number of synthetic samples that it will add will have a density distribution, whereas, for SMOTE, the distribution will be uniform. The aim here is to create synthetic data for minority examples that are harder to learn, rather than the easier ones. 
 

To sum it up, ADASYN offers the following advantages:

 It lowers the bias introduced by the class imbalance.
 
 Introduction to KNN
KNN: K-nearest neighbour is a simple, supervised machine learning algorithm used for both classification and regression tasks. It performs these tasks by identifying the neighbours that are nearest to a data point. For classification tasks, it takes the majority vote and for regression tasks, it takes the average value from the neighbours. 

 

The k in KNN specifies the number of neighbours that the algorithm should focus on. For example, if k = 3, then, for a particular test data, the algorithm observes the three nearest neighbours and takes the majority vote from them. Depending on the majority of the classes from the three nearby points, the algorithm classifies the test data.

the k value should be an odd number because you have to take the majority vote from the nearest neighbours by breaking the ties. 

 

Also, note that the k in k-means is different from the k in KNN. k in k-means stands for the number of clusters which can have any number of data points while k in KNN stands for the number of points that the model would consider to make predictions.
But what should the ideal k value be? And what happens if we change it? Let’s understand this with the help of the following diagrams which show the separation boundary between 2 classes for different values of 'k'.


KNN
As you can see, an increase in the k-value causes the decision boundary between the two classes to become smooth. 

When k = 1 for a data point, the model is observing the immediate neighbour, i.e., it is understanding the noise as well causing it to overfit the data. 
When k = 5, the model observes the five nearest neighbours for a data point. Therefore, the decision boundary starts becoming smooth.
When k = 10, the model observes the 10 nearest neighbours for a data point. Here, the decision boundary becomes smoother.
 
 Important Points: 
 Class Imbalances:

In Undersampling, you select fewer data points from the majority class for your model-building process in order to balance both the classes.
In Oversampling, you assign weights to randomly chosen data points from the minority class. It is done so that the algorithm can focus on this class while optimising the loss function.
SMOTE is a process where you can generate new data points, which lie vectorially between two data points that belong to the minority class.
ADASYN is similar to SMOTE, with a minor change i.e. the number of synthetic samples that it will add will have a density distribution. The aim here is to create synthetic data for minority examples that are harder to learn, rather than the easier ones. 
 

Model Selection & understanding:

Logistic regression works best when the data is linearly separable and needs to be interpretable. 
KNN is also highly interpretable, but not preferred when we have a huge amount of data as it will consume a lot of computation.
The decision tree model is the first choice when we want the output to be intuitive, but they tend to overfit if left unchecked.
KNN is a simple, supervised machine learning algorithm used for both classification and regression tasks. The k value in KNN should be an odd number because you have to take the majority vote from the nearest neighbours by breaking the ties. 
In Gradient Boosted machines/trees. newly added trees are trained to reduce the errors (loss function) of earlier models.
XGBoost is an extended version of gradient boosting, with additional features like regularization and parallel tree learning algorithm for finding the best split. 
Hyperparameter Tuning:

When the data is imbalanced or less, it is better to use K-Fold Cross Validation for evaluating the performance when the data set is randomly split into ‘k’ groups.
Stratified K-Fold Cross Validation is an extension of K-Fold cross-validation, in which we rearrange the data to ensure that each fold is a good representative of all the strata of the data.
When you have a small data set, the computation time will be manageable to test out different hyperparameter combinations. In this scenario, it is advised to use a grid search.
But, with large data sets, it is advised to use a randomized search because the sampling will be random and not uniform. 
 

Model Evaluation:

Accuracy is not always the correct metric for solving classification problems of imbalanced data.
Because the ROC curve is measured at all thresholds, the best threshold would be one at which the TPR is high and FPR is low, i.e., misclassifications are low.
Depending on the use case, you have to account for what you need: high precision or high recall.
 It adaptively shifts the classification decision boundary towards difficult examples.
